{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper_funcs import report_f1_results, report_accuracy, split_data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cmv_df_cleaned.csv')\n",
    "pfg_df = pd.read_csv('pfg_df_cleaned.csv')\n",
    "our_df = pd.read_csv('our_df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine our CMV and PFG dataframes into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pfg_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out the rows that have NaN as a label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the size of the cmv_df before and after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe has been reduced from 111613 down to 29465\n"
     ]
    }
   ],
   "source": [
    "size_before = len(df)\n",
    "df = df[(df['success'] == 0) | (df['success'] == 1)]\n",
    "size_after = len(df)\n",
    "print(f\"Size of the dataframe has been reduced from {size_before} down to {size_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(list(df['success']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataframe and labels array into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 8\n",
    "dfs = np.split(df, num_chunks)\n",
    "labels = np.split(labels, num_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a list of unique words in all persuader conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set([word for conversation in df[\"conversation\"] for word in conversation.split()]))\n",
    "unique_words_dict = {word: idx for idx, word in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the unique words to create our BoW feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow_feature(conversation):\n",
    "    feature = [0] * len(unique_words)\n",
    "    for word in conversation.split():\n",
    "        idx = unique_words_dict[word] if word in unique_words_dict else None\n",
    "        if idx is not None:\n",
    "            feature[idx ] += 1\n",
    "\n",
    "    return np.array(feature)\n",
    "\n",
    "bow_matrices = []\n",
    "\n",
    "for idx in range(len(dfs)):\n",
    "    bow_matrices.append(np.array([generate_bow_feature(conversation) for conversation in dfs[idx][\"conversation\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels):\n",
    "    # parameters = [{'kernel': ['rbf'], 'C':[1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}]\n",
    "\n",
    "    svm = SVC(kernel='rbf', C=1000, gamma=0.001)\n",
    "    # svm = SVC()\n",
    "    # clf = GridSearchCV(svm, parameters, verbose=2)\n",
    "    # clf.fit(features, labels)\n",
    "    svm.fit(features, labels)\n",
    "\n",
    "    # Return the trained model\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(features, labels, model, feature_type=\"No Feature Type Provided\"):\n",
    "    label_predictions = model.predict(features)\n",
    "    accuracy = accuracy_score(list(labels), label_predictions)\n",
    "    report_accuracy(accuracy, feature_type, \"sklearn SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into testing and training subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs = []\n",
    "test_xs = []\n",
    "train_ys = []\n",
    "test_ys = []\n",
    "\n",
    "for idx, matrix in enumerate(bow_matrices):\n",
    "    train_x, test_x, \\\n",
    "        train_y, test_y = split_data(matrix, labels[idx])\n",
    "    \n",
    "    train_xs.append(train_x)\n",
    "    test_xs.append(test_x)\n",
    "    train_ys.append(train_y)\n",
    "    test_ys.append(test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the sklearn SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 8 / 8\r"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(zip(train_xs, train_ys)):\n",
    "    print(f\"Training model {idx + 1} / {len(train_xs)}\", end='\\r')\n",
    "    model = train(x, y)\n",
    "    joblib.dump(model, f\"./models/{idx}_bow_svm_model.pkl\")\n",
    "    del(model) # This might not be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(model, \"./models/0_tfidf_svm_model.pkl\")\n",
    "# joblib.load(\"./models/0_tfidf_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bag of Words Model #1]\t[sklearn SVM]\t\tAccuracy: 78.15%\n",
      "[Bag of Words Model #2]\t[sklearn SVM]\t\tAccuracy: 75.58%\n",
      "[Bag of Words Model #3]\t[sklearn SVM]\t\tAccuracy: 78.02%\n",
      "[Bag of Words Model #4]\t[sklearn SVM]\t\tAccuracy: 78.43%\n",
      "[Bag of Words Model #5]\t[sklearn SVM]\t\tAccuracy: 79.10%\n",
      "[Bag of Words Model #6]\t[sklearn SVM]\t\tAccuracy: 78.56%\n",
      "[Bag of Words Model #7]\t[sklearn SVM]\t\tAccuracy: 75.98%\n",
      "[Bag of Words Model #8]\t[sklearn SVM]\t\tAccuracy: 81.14%\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(zip(test_xs, test_ys)):\n",
    "    model = joblib.load(f\"./models/{idx}_bow_svm_model.pkl\")\n",
    "    test(test_xs[idx], test_ys[idx], model, f\"Bag of Words Model #{idx + 1}\")\n",
    "    del(model) # This might not be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(f\"./models/1_bow_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate the features for our conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_labels = [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
    "# our_labels = [0, 0, 0, 0, 1, 0, 0, 1]\n",
    "our_labels = [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(Y):\n",
    "    total = len(our_labels)\n",
    "    correct = 0\n",
    "    for idx, label in enumerate(Y):\n",
    "        if label == our_labels[idx]:\n",
    "            correct = correct + 1\n",
    "    \n",
    "    return (correct / total) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.56%] [1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[55.56%] [1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[22.22%] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[77.78%] [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[77.78%] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[83.33%] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[72.22%] [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8, 1):\n",
    "    model = joblib.load(f\"./models/{i}_bow_svm_model.pkl\")\n",
    "    our_features = []\n",
    "    for conversation in our_df[\"conversation\"]:\n",
    "        our_features.append(generate_bow_feature(conversation)[:-1])\n",
    "    predictions = model.predict(our_features)\n",
    "    print(f\"[{get_accuracy(predictions):.2f}%] {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.00%] [1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[75.00%] [1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[25.00%] [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[75.00%] [0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[87.50%] [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[87.50%] [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[87.50%] [0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8, 1):\n",
    "    model = joblib.load(f\"./models/{i}_bow_svm_model.pkl\")\n",
    "    our_features = []\n",
    "    for conversation in our_df[\"conversation\"]:\n",
    "        our_features.append(generate_bow_feature(conversation)[:-1])\n",
    "    predictions = model.predict(our_features)\n",
    "    print(f\"[{get_accuracy(predictions):.2f}%] {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[53.33%] [1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0.]\n",
      "30\n",
      "[43.33%] [1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 1. 1.]\n",
      "30\n",
      "[13.33%] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "30\n",
      "[76.67%] [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n",
      "30\n",
      "[80.00%] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n",
      "30\n",
      "[80.00%] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n",
      "30\n",
      "[76.67%] [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8, 1):\n",
    "    model = joblib.load(f\"./models/{i}_bow_svm_model.pkl\")\n",
    "    our_features = []\n",
    "    for conversation in our_df[\"conversation\"]:\n",
    "        our_features.append(generate_bow_feature(conversation)[:-1])\n",
    "    predictions = model.predict(our_features)\n",
    "    print(f\"[{get_accuracy(predictions):.2f}%] {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_predictions = model.predict(our_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hello today well thank plan day really live ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>want thank much welcome hope great day thank m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wow plant grow quickly know excited see look l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wu wu tang clan american hip hop group formed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>awesome angry yesterday go back house working ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         conversation\n",
       "12  hello today well thank plan day really live ch...\n",
       "13  want thank much welcome hope great day thank m...\n",
       "14  wow plant grow quickly know excited see look l...\n",
       "15  wu wu tang clan american hip hop group formed ...\n",
       "16  awesome angry yesterday go back house working ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb69f1298249730a38e9c908db43e5574824b46301e1be803b6723b7b558f467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
